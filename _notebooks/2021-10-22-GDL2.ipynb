{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021-10-22-GDL2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XZuXYfmJPu3l"},"source":["# 2\n","> GDL\n","\n","- toc: true \n","- badges: true\n","- comments: false\n","- categories: [jupyter]\n"]},{"cell_type":"markdown","metadata":{"id":"e6t_Gqemxl1t"},"source":["# geometric deep learning models "]},{"cell_type":"markdown","metadata":{"id":"tQPGhUITsfZ0"},"source":["## <font color=\"green\">2.1 ... tensors in pytorch</font>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZosyKQ2wsne5","executionInfo":{"status":"ok","timestamp":1634929222638,"user_tz":300,"elapsed":134612,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"51d8f4f5-7670-43ee-8f02-425e900d8fd8"},"source":["pip install torch --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n","Collecting torch\n","  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:38tcmalloc: large alloc 1147494400 bytes == 0x5560b83a0000 @  0x7fe0f2a0d615 0x55607f4604cc 0x55607f54047a 0x55607f4632ed 0x55607f554e1d 0x55607f4d6e99 0x55607f4d19ee 0x55607f464bda 0x55607f4d6d00 0x55607f4d19ee 0x55607f464bda 0x55607f4d3737 0x55607f555c66 0x55607f4d2daf 0x55607f555c66 0x55607f4d2daf 0x55607f555c66 0x55607f4d2daf 0x55607f465039 0x55607f4a8409 0x55607f463c52 0x55607f4d6c25 0x55607f4d19ee 0x55607f464bda 0x55607f4d3737 0x55607f4d19ee 0x55607f464bda 0x55607f4d2915 0x55607f464afa 0x55607f4d2c0d 0x55607f4d19ee\n","\u001b[K     |████████████████████████████████| 881.9 MB 18 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu111\n","    Uninstalling torch-1.9.0+cu111:\n","      Successfully uninstalled torch-1.9.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"S-LV_wGXsuvE"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.utils.data as data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cX0uHvDgsvnP","executionInfo":{"status":"ok","timestamp":1634929223441,"user_tz":300,"elapsed":10,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"3cfed967-62db-45d7-ba35-29a9360202dd"},"source":["torch.manual_seed(42)\n","print(\"Using torch\", torch.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using torch 1.10.0+cu102\n"]}]},{"cell_type":"markdown","metadata":{"id":"kvKKEvc-3a2k"},"source":["### <font color=\"teal\">... helper classes and functions </font>"]},{"cell_type":"code","metadata":{"id":"aF4K6jD7e8GR"},"source":["from PIL import Image\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wft7v5Cyc1q2","executionInfo":{"status":"ok","timestamp":1634930494878,"user_tz":300,"elapsed":5049,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"932cb85c-c9df-4dcf-a8fd-c122b53cde41"},"source":["!pip install tabletext"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tabletext\n","  Downloading tabletext-0.1.tar.gz (6.1 kB)\n","Building wheels for collected packages: tabletext\n","  Building wheel for tabletext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tabletext: filename=tabletext-0.1-py3-none-any.whl size=6022 sha256=384237e663e1e0614b9290fcd435e0e01872c35657dbc01661714520ea433992\n","  Stored in directory: /root/.cache/pip/wheels/cc/ae/ab/697f6cd9887c63663da889f796c2c7ea280bc407b16f6fd081\n","Successfully built tabletext\n","Installing collected packages: tabletext\n","Successfully installed tabletext-0.1\n"]}]},{"cell_type":"code","metadata":{"id":"K4BKiUW4c5R-"},"source":["from tabletext import to_text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kdHDqVYPS8iZ"},"source":["___\n","\n","#### method ... `info`\n","\n","_can currently handle 1- and 2-tensors_"]},{"cell_type":"code","metadata":{"id":"4CvwztRRSKPI","executionInfo":{"status":"ok","timestamp":1634949349581,"user_tz":300,"elapsed":147,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}}},"source":["#collapse-hide\n","\n","def info(obj, name):\n","\n","    ty_tens = type( torch.tensor([2]) )\n","\n","    ty_np = type( np.array([2]) )\n","\n","    delim = \"   \"\n","\n","    if obj.ndim == 1:\n","\n","        display_obj = obj[None,:]\n","\n","    elif obj.ndim == 2:\n","\n","        display_obj = obj\n","\n","    if type(obj) == ty_tens:\n","\n","        print( \"tensor\", delim, name, \"\\n\" )\n","\n","        print( delim, \"num. dims   \", delim, obj.ndim )\n","\n","        print( delim, \"num. entries\", delim, np.array( obj ).size )\n","\n","        print( delim, \"shape       \", delim, np.array( obj.size() ) )\n","\n","    if type(obj) == ty_np:\n","\n","        print( \"np array\", delim, name, \"\\n\" )\n","\n","        print( delim, \"number of dimensions\", obj.ndim )\n","\n","        print( delim, \"number of entries\", delim, obj.size )\n","\n","        print( delim, \"shape\", delim, obj.shape )\n","\n","    print(\"\\n\")\n","\n","    display_list = display_obj.tolist()\n","\n","    J = len( display_list )\n","    K = len( display_list[0])\n","\n","    outer_list = []\n","\n","    for j in range(J):\n","\n","        inner_list = []\n","\n","        for k in range(K):\n","\n","            inner_list += [ str( display_list[j][k] )[:4] ]\n","\n","        outer_list += [ inner_list ]\n","\n","    print( to_text( outer_list ) )\n","\n","    print(\"\\n\\n\")"],"execution_count":267,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kw4sHooPSKY3"},"source":["___"]},{"cell_type":"markdown","metadata":{"id":"WZ4ZHjHsDpzL"},"source":["___\n","\n","#### method ... `viz_tens`\n","\n","args\n","\n","* `tens`\n","\n","* `display_size`"]},{"cell_type":"code","metadata":{"id":"OoDw8dGfDp9x","executionInfo":{"status":"ok","timestamp":1634949350397,"user_tz":300,"elapsed":3,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}}},"source":["#collapse-hide\n","def viz_tens( tens, display_size = 2 ):\n","\n","    size = display_size\n","\n","    if tens.ndim == 1:\n","\n","        display_obj = tens[None,:]\n","\n","        display_obj = display_obj.float()\n","\n","    elif tens.ndim == 2:\n","\n","        display_obj = tens\n","\n","        display_obj = display_obj.float()\n","\n","    pil_image = transforms.ToPILImage()( display_obj ).convert(\"RGB\")\n","\n","    fig = plt.figure( figsize = (size, size) )\n","\n","    f_rows, f_cols = 1, 1\n","\n","    fig.add_subplot( f_rows, f_cols, 1 )\n","\n","    plt.tick_params( left = False, bottom = False )\n","\n","    plt.axis('off')\n","\n","    plt.imshow(pil_image)"],"execution_count":268,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rt5ZSh3hDqHf"},"source":["___"]},{"cell_type":"markdown","metadata":{"id":"c0Sde9xlCy2g"},"source":["___\n","\n","#### method ... `viz_tens_list`\n","\n","args\n","\n","* `list_of_tensors`\n","\n","* `display_size = 6`"]},{"cell_type":"code","metadata":{"id":"97XsQAdKzzmP","executionInfo":{"status":"ok","timestamp":1634949350538,"user_tz":300,"elapsed":3,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}}},"source":["#collapse-hide\n","def viz_tens_list( list_of_tensors, display_size = 6 ):\n","\n","    size = display_size\n","\n","    image_list = [ transforms.ToPILImage()(x).convert(\"RGB\") for x in list_of_tensors ]\n","\n","    tensor_list = [ transforms.ToTensor()(image) for image in image_list]\n","\n","    grid = torchvision.utils.make_grid( tensor_list, padding = 2, pad_value = 1.0 )\n","\n","    grid_pil = transforms.ToPILImage()(grid).convert(\"RGB\")\n","\n","    fig = plt.figure( figsize = (size, size) )\n","\n","    f_rows, f_cols = 1, 1\n","\n","    fig.add_subplot( f_rows, f_cols, 1 )\n","\n","    plt.tick_params( left = False, bottom = False )\n","\n","    plt.axis('off')\n","\n","    plt.imshow(grid_pil)"],"execution_count":269,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HKxCdUGbaEQq"},"source":["___"]},{"cell_type":"markdown","metadata":{"id":"QFT00Jsas_l2"},"source":["### <font color=\"teal\">... initializing tensors</font>"]},{"cell_type":"markdown","metadata":{"id":"8Z5-7ZoXtXXv"},"source":["Tensors are similar to NumPy's `ndarrays`, except that tensors can run on GPUs or other hardware accelerators. Tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data. Tensors are also optimized for automatic differentiation\n"]},{"cell_type":"markdown","metadata":{"id":"YH8sJWhJtY_w"},"source":["Here are some ways they can be initialized in torch.\n","\n","1. from lists: $\\quad$ `X_1 = torch.tensor( list_object )`\n","\n","2. from a numpy array $\\quad$ `X_2 = torch.from_numpy( array_object )`\n","\n","3. with random or constant values, of a given shape. For example,\n","\n","    a. entries all ones: $\\quad$ `X_3_a = torch.ones( shape )`\n","\n","    b. entries all zeros $\\quad$ `X_3_b = torch.zeros( shape )`\n","\n","    c. entries are i.i.d. $\\text{Unif}(0,1)$ $\\quad$ `X_3_c = torch.rand( shape )`\n","\n","    d. entries are i.i.d. standard normal $\\quad$ `X_3_d = torch.randn( shape )`\n","\n","    e. from values stored in memory $\\quad$ `X_3_e = torch.Tensor( shape )`\n","    \n","    f. a list of consecutive integers between $N$ and $M$, inclusive, as tensor object $\\quad$ `X_3_f = torch.arange(N,M)`"]},{"cell_type":"markdown","metadata":{"id":"FWdPusy12fp4"},"source":["#### ... 1.   from lists"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"id":"CfPAEk8N2TcU","executionInfo":{"status":"ok","timestamp":1634949351743,"user_tz":300,"elapsed":383,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"31efc148-2743-41da-bb27-615fb698230f"},"source":["#collapse-hide\n","X_1 = torch.tensor( [ 2, 3 ] )\n","info(X_1, \"X1\")\n","viz_tens( 25 * X_1 ) # the factor there to help distinguish values"],"execution_count":270,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X1 \n","\n","    num. dims        1\n","    num. entries     2\n","    shape            [2]\n","\n","\n","┌───┬───┐\n","│ 2 │ 3 │\n","└───┴───┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABGCAYAAAAKCiBIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAA2klEQVR4nO3dsQ0CIBBAUTFOx/KMwRg4gXaGxP9ee80lP1dQMc45D3qetxfgDuGjhI8SPkr4KOGjXt+Ga62/fuvtvW+v8FNzzvFp5uKjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPmr4RrzJxUcJHyV8lPBRwkcJH/UGmigNh5tk3yoAAAAASUVORK5CYII=\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"SrAFRNFN4l79"},"source":["#### ... 2. from numpy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"15BQPXcG4rF1","executionInfo":{"status":"ok","timestamp":1634949355023,"user_tz":300,"elapsed":352,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"ea8a173e-07fa-4b6f-8cf8-386fbb4e4dd5"},"source":["#collapse-hide\n","X_2 = torch.from_numpy( np.array( [ 2, 3, 4 ] ) )\n","info(X_2, \"'X two'\")\n","viz_tens( 25 * X_2 )"],"execution_count":271,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     'X two' \n","\n","    num. dims        1\n","    num. entries     3\n","    shape            [3]\n","\n","\n","┌───┬───┬───┐\n","│ 2 │ 3 │ 4 │\n","└───┴───┴───┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAAAzCAYAAABR5bw6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAAsklEQVR4nO3csQ0DIRAAQWO5UwqmDMrgG7Cd/ks7k15y0uoCEsY550XP++4FuIfwUcJHCR8lfJTwUZ9/w7XW4956e++7V/jqiXvNOcevmYuPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4a/bJtcfJTwUcJHCR8lfJTwURc1fBBhoRLH+gAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"KX8wXz3IQ7_b"},"source":["The next examples allow a shape to be provided as an argument. "]},{"cell_type":"code","metadata":{"id":"_E3I4VRyS9rv","executionInfo":{"status":"ok","timestamp":1634949356531,"user_tz":300,"elapsed":162,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}}},"source":["#collapse-hide\n","\n","shape_dict = {}\n","\n","shape_dict[\"i\"] = ( 3 )\n","\n","shape_dict[\"ii\"] = ( 2, 3 )\n","\n","shape_dict[\"iii\"] = ( 2, 3, )"],"execution_count":272,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7l6vDAE5rGh"},"source":["#### ... 3. (a) ones of given shape"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EU78SXCK5uCO","executionInfo":{"status":"ok","timestamp":1634949358005,"user_tz":300,"elapsed":541,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"82c18352-17e5-44c6-b262-b6c921fca0cf"},"source":["#collapse-hide\n","\n","for key in shape_dict:\n","    s = key\n","    X_3_a = torch.ones(shape_dict[s])\n","    info(X_3_a, \"'X three (a)'\"[:-1] + \" \" + s + \"'\" )\n","    viz_tens( 25 * X_3_a )"],"execution_count":273,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     'X three (a) i' \n","\n","    num. dims        1\n","    num. entries     3\n","    shape            [3]\n","\n","\n","┌─────┬─────┬─────┐\n","│ 1.0 │ 1.0 │ 1.0 │\n","└─────┴─────┴─────┘\n","\n","\n","\n","tensor     'X three (a) ii' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌─────┬─────┬─────┐\n","│ 1.0 │ 1.0 │ 1.0 │\n","├─────┼─────┼─────┤\n","│ 1.0 │ 1.0 │ 1.0 │\n","└─────┴─────┴─────┘\n","\n","\n","\n","tensor     'X three (a) iii' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌─────┬─────┬─────┐\n","│ 1.0 │ 1.0 │ 1.0 │\n","├─────┼─────┼─────┤\n","│ 1.0 │ 1.0 │ 1.0 │\n","└─────┴─────┴─────┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAAAzCAYAAABR5bw6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAAqElEQVR4nO3csQ2AMAwAQYIYIvtPly3CBNAi9Hetm0gvF24y9t4HPefXD+AbwkcJHyV8lPBRwkddb8O1llvvx+ac42lm46OEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svio4S/bJhsfJXyU8FHCRwkfJXzUDUneCmEkcikWAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAA/UlEQVR4nO3WwQkDMQwAwTikCPdfnbvQVZB8TdiZrz6CRaA1My963rcX4A7ho4SPEj5K+KjPr+E5x8v/x/be69vMxUcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJH7Vm5vYOXODio4SPEj5K+Cjho4SPegDe4Qqr0aiDOwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAA/UlEQVR4nO3WwQkDMQwAwTikCPdfnbvQVZB8TdiZrz6CRaA1My963rcX4A7ho4SPEj5K+KjPr+E5x8v/x/be69vMxUcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJH7Vm5vYOXODio4SPEj5K+Cjho4SPegDe4Qqr0aiDOwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"_N4bM_vF7Up4"},"source":["#### ... 3. (b) zeros of given shape"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vRQbqdB-qmfx","executionInfo":{"status":"ok","timestamp":1634949359927,"user_tz":300,"elapsed":603,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"dfa6f9e9-0ef3-4c21-c80c-a25faa9e8313"},"source":["#collapse-hide\n","\n","for key in shape_dict:\n","    s = key\n","    X_3_b = torch.zeros(shape_dict[s])\n","    info(X_3_b, \"'X three (a)'\"[:-1] + \" \" + s + \"'\" )\n","    viz_tens( 25 * X_3_b )"],"execution_count":274,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     'X three (a) i' \n","\n","    num. dims        1\n","    num. entries     3\n","    shape            [3]\n","\n","\n","┌─────┬─────┬─────┐\n","│ 0.0 │ 0.0 │ 0.0 │\n","└─────┴─────┴─────┘\n","\n","\n","\n","tensor     'X three (a) ii' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌─────┬─────┬─────┐\n","│ 0.0 │ 0.0 │ 0.0 │\n","├─────┼─────┼─────┤\n","│ 0.0 │ 0.0 │ 0.0 │\n","└─────┴─────┴─────┘\n","\n","\n","\n","tensor     'X three (a) iii' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌─────┬─────┬─────┐\n","│ 0.0 │ 0.0 │ 0.0 │\n","├─────┼─────┼─────┤\n","│ 0.0 │ 0.0 │ 0.0 │\n","└─────┴─────┴─────┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAAAzCAYAAABR5bw6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAAo0lEQVR4nO3cMQqAQAwAQSP+/8vxBdqK7Eyb5mBJkeZmdw96zq8fwDeEjxI+Svgo4aOEj7rehjPj1vux3Z2nmY2PEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho8Zftk02Pkr4KOGjhI8SPkr4qBuM0wphyOWPswAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAA+ElEQVR4nO3WsQnEQAwAwdfj/luWK7DTw+xMqkSwCDS7+6Pnf3oBzhA+Svgo4aOEj7rehjPj5f+w3Z2nmYuPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5qdvf0Dhzg4qOEjxI+Svgo4aOEj7oBIeUKq3KMmaAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAA+ElEQVR4nO3WsQnEQAwAwdfj/luWK7DTw+xMqkSwCDS7+6Pnf3oBzhA+Svgo4aOEj7rehjPj5f+w3Z2nmYuPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5qdvf0Dhzg4qOEjxI+Svgo4aOEj7oBIeUKq3KMmaAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"lX5iyNSa7ZNg"},"source":["#### ... 3. (c) i.i.d. uniform of given shape"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Sh28SUSjruFw","executionInfo":{"status":"ok","timestamp":1634949362113,"user_tz":300,"elapsed":324,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"5ad5640a-8e93-47a8-c257-f3a232a7ec99"},"source":["#collapse-hide\n","\n","for key in shape_dict:\n","    s = key\n","    X_3_c = torch.rand(shape_dict[s])\n","    info(X_3_c, \"X 3 (c) \" + \" \" + s )\n","    viz_tens( 25 * X_3_c )\n"],"execution_count":275,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X 3 (c)  i \n","\n","    num. dims        1\n","    num. entries     3\n","    shape            [3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.31 │ 0.62 │ 0.73 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","tensor     X 3 (c)  ii \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.43 │ 0.30 │ 0.77 │\n","├──────┼──────┼──────┤\n","│ 0.10 │ 0.81 │ 0.30 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","tensor     X 3 (c)  iii \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.50 │ 0.40 │ 0.56 │\n","├──────┼──────┼──────┤\n","│ 0.34 │ 0.86 │ 0.48 │\n","└──────┴──────┴──────┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAAAzCAYAAABR5bw6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAAs0lEQVR4nO3csQ0DIRAAQWO5/07I6Ioi+AZsp//SzqSXnLS6gIRxznnR8757Ae4hfJTwUcJHCR8lfNTn33Dv/bi33lrr7hW+euJec87xa+bio4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+Cjho4SPEj5K+KjhL9smFx8lfJTwUcJHCR8lfNQFvK0QYWkLuqsAAAAASUVORK5CYII=\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABJ0lEQVR4nO3csW2EQBRFUWNteZRIDr3QAgmVjAvweuVNPJbuOekkT7r6EhHLGOODns/ZA5hD+Cjho4SPEj7q8erxvu9/98m/7/vsCU9d1zV7wjfbti0/vbn4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPurlz4+O4/irHb92nufsCU+t6zp7wltcfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfJTwUcJHCR8lfNQyxpi9gQlcfJTwUcJHCR8lfJTwUV/XbBXqvW4F4QAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABK0lEQVR4nO3csW2EQBBAUWM5okOqu4gCKIUKaIMMx9bdke7J/710k5G+Rtpopuu6vuj5Hj0AYwgfJXyU8FHCR/3cPa7r+nFf/mVZRo/w0nmeo0d4Ms/z9O7NxkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBR091J023bPu740b7vo0d46fF4jB7hyXEcjh/xl/BRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81O3VK/4vGx8lfJTwUcJHCR8lfNQvrVYap4dmmBYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"DpBCD-VT7mFF"},"source":["#### ... 3. (d) i.i.d. standard normal of given shape"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bZ9SYjRcsE9L","executionInfo":{"status":"ok","timestamp":1634949379119,"user_tz":300,"elapsed":549,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"4c98dd24-c504-4304-996d-4cbbe6da6561"},"source":["#collapse-hide\n","\n","for key in shape_dict:\n","    s = key\n","    X_3_d = torch.randn(shape_dict[s])\n","    info(X_3_d, \"X 3 (d)\" + \" \" + s )\n","    viz_tens( 25 * X_3_d )"],"execution_count":277,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X 3 (d) i \n","\n","    num. dims        1\n","    num. entries     3\n","    shape            [3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.91 │ 0.84 │ -0.0 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","tensor     X 3 (d) ii \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.57 │ -0.9 │ -0.9 │\n","├──────┼──────┼──────┤\n","│ -0.2 │ -0.9 │ 1.85 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","tensor     X 3 (d) iii \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ -0.2 │ 0.25 │ 1.49 │\n","├──────┼──────┼──────┤\n","│ 0.53 │ -0.1 │ 0.34 │\n","└──────┴──────┴──────┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAAAzCAYAAABR5bw6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAAuElEQVR4nO3cuQ3DMBAAQdNwOyxHxaoA1UUX4CelgJ1JLzlgcQETjrXWg57n7gXYQ/go4aOEjxI+Svio17/heZ63e+sdx7F7ha+u69q9woc55/g1c/FRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81PCXbZOLjxI+Svgo4aOEjxI+6g2sng1hoDkvEQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABK0lEQVR4nO3csW2EQBBAUWO5KZoiuK7IaIBK6IMUx9bdke7J/710k5G+Rtpopuu6vuj5Hj0AYwgfJXyU8FHCR/3cPS7L8nFf/nVdR4/w0rZto0d4Ms/z9O7NxkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBR091J0+M4Pu740ePxGD3CS+d5jh7hyb7vjh/xl/BRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81O3VK/4vGx8lfJTwUcJHCR8lfNQvTl4ap2sIn/cAAAAASUVORK5CYII=\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABJ0lEQVR4nO3csWnEQBRFUctsqkTtqTU1MP2on3EBXi92smO456STPLh8UKRtzvlBz+fqAawhfJTwUcJHCR/1ePV4Xde/++QfY6ye8NRxHKsnfDPG2H56c/FRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81MufH933/a4dv3ae5+oJT+37vnrCn7j4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4qG3OuXoDC7j4KOGjhI8SPkr4KOGjvgDNEhFhIv9kaAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"JwY4smEXs9Gm"},"source":["#### ... 3. (f) sequence"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"O2oQdYhktbUi","executionInfo":{"status":"ok","timestamp":1634949401236,"user_tz":300,"elapsed":322,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"fad90b75-3583-4b72-c74a-b43c3db43d74"},"source":["#collapse-hide\n","\n","X_3_f = torch.arange(10,20) \n","info(X_3_f, \"X 3 (f)\")\n","viz_tens( 25 * X_3_f ) # note the modular arith. being performed automatically"],"execution_count":278,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X 3 (f) \n","\n","    num. dims        1\n","    num. entries     10\n","    shape            [10]\n","\n","\n","┌────┬────┬────┬────┬────┬────┬────┬────┬────┬────┐\n","│ 10 │ 11 │ 12 │ 13 │ 14 │ 15 │ 16 │ 17 │ 18 │ 19 │\n","└────┴────┴────┴────┴────┴────┴────┴────┴────┴────┘\n","\n","\n","\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAAAZCAYAAAD30ppqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAAf0lEQVRoge3awQnAIBAAwVwIXP/t2cCVcakgwTzEwO58FRUWH4LR3Yd4zt0H0B6GhzI8lOGhDA9leKjrbTAzp996VTW96Ze5K9f+w9yVa48x4mnMGw9leCjDQxkeyvBQhocyPJThoQwPZXio8AcOkzceyvBQhocyPJThoQwPdQM4ZCIt7yfBxgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"c2_VNHBYt4Cb"},"source":["### <font color=\"teal\">numpy objects and tensors</font>"]},{"cell_type":"markdown","metadata":{"id":"m-3HAcmauOR_"},"source":["Tensors can be converted to numpy arrays, and numpy arrays back to tensors.\n","To transform a numpy array into a tensor, we can use the function `torch.from_numpy`, and we use `np.array` for the other direction."]},{"cell_type":"markdown","metadata":{"id":"O2CfkAyIwDZG"},"source":["The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU.\n","\n","In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand.\n","Hence, you get a line like `np_arr = tensor.cpu().numpy()`."]},{"cell_type":"markdown","metadata":{"id":"Wi-IudDowL3g"},"source":["Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xuMNCnWhwSFw","executionInfo":{"status":"ok","timestamp":1634949406923,"user_tz":300,"elapsed":136,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"37628930-b70c-47f7-b1bf-794c5db89805"},"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"],"execution_count":279,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAfGPmNLwUCt","executionInfo":{"status":"ok","timestamp":1634949407384,"user_tz":300,"elapsed":6,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"e0bc4d67-f3f7-4704-f86a-65ea240e03b8"},"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"],"execution_count":280,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"markdown","metadata":{"id":"rD8WrGTVtfnb"},"source":["### <font color=\"teal\">... tensor operations</font>"]},{"cell_type":"markdown","metadata":{"id":"fgOtJXKztkeQ"},"source":["Most operations existing in numpy also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#).\n","\n","* Each torch operation can be run on the GPU.\n","\n","* By default, tensors are created on the CPU. Unless we are using a package like `pytorch-lightning`, we need to explicitly move tensors to the GPU using the `.to` method, after checking GPU availability. \n","\n","* Copying large tensors across devices can be expensive in terms of time and memory.\n"]},{"cell_type":"markdown","metadata":{"id":"YyKSQh8pwkXX"},"source":["#### ... adding tensors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"vL5_gbFdGouM","executionInfo":{"status":"ok","timestamp":1634949429135,"user_tz":300,"elapsed":363,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"223b3acb-6644-48a0-dd16-792fec8dcd10"},"source":["#collapse-hide\n","\n","X_1, X_2 = torch.rand(2,3), torch.rand(2,3)\n","viz_tens_list( [ X_1, X_2 ] )"],"execution_count":282,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV0AAAC1CAYAAAD86CzsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAC/UlEQVR4nO3asW3CYBhF0ThySY0YwwuwCROwCyPQMQ2VW0ahchYIoDTXKJzTfsVzdfUXHpZl+QKg8b32BwB8EtEFCIkuQEh0AUKiCxAaX9z92gDwd8Ojg5cuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAoXHtD1jTdrtN9263W7q32+3Svfv9nu6V5nlO9y6XS7p3OBzSvWma0r134qULEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoTGtT9gTdfrNd07nU7p3vF4TPf+s81mk+6dz+d0b7/fp3vTNKV778RLFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIDcuyPLs/PQLwq+HRwUsXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2A0PjiPiRfAfAhvHQBQqILEBJdgJDoAoREFyAkugChH2q5HfH36JPyAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"XfB72xmXwvAf","executionInfo":{"status":"ok","timestamp":1634949434017,"user_tz":300,"elapsed":336,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"5872a8b1-a033-4d77-aac8-9273b67e54cf"},"source":["#collapse-hide\n","\n","Y = X_1 + X_2\n","viz_tens(Y) "],"execution_count":283,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAH4AAABYCAYAAAAz1kOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABLElEQVR4nO3cu22EUBRFUWO5GWiFdohpk4yMOnAB89FEfpb2WulLjrR1JSKm+76/6PkePYAxhI8SPkr4KOGjft49Xtf17z75930fPeGpbdtGT3gwz/P06s3FRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FHCRwkfJXyU8FFvf350HMdf7fjYsiyjJzy1ruvoCQ/O83z55uKjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjhI8SPkr4KOGjpvu+R29gABcfJXyU8FHCRwkfJXzUL5y0FCs2rBfAAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 144x144 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"9d_36o-r0emo"},"source":["#### ... stacking tensors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmrgRs7Go4he","executionInfo":{"status":"ok","timestamp":1634949440608,"user_tz":300,"elapsed":142,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"b51d777e-26ea-4eb4-89e0-51f7f85a079d"},"source":["#collapse-hide\n","\n","X_1, X_2 = torch.arange(5,10), torch.arange(10,15)\n","\n","info(X_1, \"X 1\")\n","\n","info(X_2, \"X 2\")"],"execution_count":284,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X 1 \n","\n","    num. dims        1\n","    num. entries     5\n","    shape            [5]\n","\n","\n","┌───┬───┬───┬───┬───┐\n","│ 5 │ 6 │ 7 │ 8 │ 9 │\n","└───┴───┴───┴───┴───┘\n","\n","\n","\n","tensor     X 2 \n","\n","    num. dims        1\n","    num. entries     5\n","    shape            [5]\n","\n","\n","┌────┬────┬────┬────┬────┐\n","│ 10 │ 11 │ 12 │ 13 │ 14 │\n","└────┴────┴────┴────┴────┘\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCZCoLoypwe4","executionInfo":{"status":"ok","timestamp":1634949445207,"user_tz":300,"elapsed":163,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"bbc32eb6-2eb6-44d6-d979-99c0b5e4811a"},"source":["#collapse-hide\n","\n","Y = torch.stack([X_1, X_2], dim = 0)\n","info(Y, \"Y\")"],"execution_count":285,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     Y \n","\n","    num. dims        2\n","    num. entries     10\n","    shape            [2 5]\n","\n","\n","┌────┬────┬────┬────┬────┐\n","│ 5  │ 6  │ 7  │ 8  │ 9  │\n","├────┼────┼────┼────┼────┤\n","│ 10 │ 11 │ 12 │ 13 │ 14 │\n","└────┴────┴────┴────┴────┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"vsFE3lVSxiqT"},"source":["#### ... in-place operations"]},{"cell_type":"markdown","metadata":{"id":"xqGLzbThyCcm"},"source":["Operations that store the result into the operand are called _in-place_. They are  usually marked with a underscore postfix, e.g. \"`add_`\" instead of \"`add`\". The operation `X.copy_(Y)` will change `X`."]},{"cell_type":"markdown","metadata":{"id":"_fluWRXzyG5D"},"source":["Calling `x1 + x2` creates a new tensor containing the sum of the two inputs.\n","However, we can also use in-place operations that are applied directly on the memory of a tensor.\n","We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation.\n","An example is shown below:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBA_fQJYycd2","executionInfo":{"status":"ok","timestamp":1634949452103,"user_tz":300,"elapsed":165,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"ab72aff1-107e-4540-db06-80611af4cfb0"},"source":["#collapse-hide\n","\n","X_1, X_2 = torch.rand(2, 3), torch.rand(2, 3)\n","print(\"\\t\",\"before\", \"\\n\")\n","info(X_1, \"'X one'\")\n","info(X_2, \"'X two'\")\n","\n","print(\"\\n\\n\")\n","\n","X_2.add_(X_1)\n","print(\"\\t\",\"after\",\"\\n\")\n","info(X_1, \"'X one'\")\n","info(X_2, \"'X two'\")"],"execution_count":286,"outputs":[{"output_type":"stream","name":"stdout","text":["\t before \n","\n","tensor     'X one' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.59 │ 0.60 │ 0.57 │\n","├──────┼──────┼──────┤\n","│ 0.63 │ 0.25 │ 0.43 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","tensor     'X two' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.97 │ 0.83 │ 0.48 │\n","├──────┼──────┼──────┤\n","│ 0.02 │ 0.52 │ 0.15 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","\n","\n","\n","\t after \n","\n","tensor     'X one' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 0.59 │ 0.60 │ 0.57 │\n","├──────┼──────┼──────┤\n","│ 0.63 │ 0.25 │ 0.43 │\n","└──────┴──────┴──────┘\n","\n","\n","\n","tensor     'X two' \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌──────┬──────┬──────┐\n","│ 1.56 │ 1.44 │ 1.05 │\n","├──────┼──────┼──────┤\n","│ 0.66 │ 0.78 │ 0.59 │\n","└──────┴──────┴──────┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"G9qBA5rQyHqP"},"source":["> In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged. "]},{"cell_type":"markdown","metadata":{"id":"v31LbYKfyyEi"},"source":["#### ... reshaping tensors"]},{"cell_type":"markdown","metadata":{"id":"nocsFb5Ly0g9"},"source":["Another common operation aims at changing the shape of a tensor.\n","A tensor of size `(2,3)` can be re-organized to any other shape with the same number of elements (e.g. a tensor of size `(6)`, or `(3,2)`, ...).\n","\n","In PyTorch, this reshaping operation is called `view`:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5ZiVTnqy3K4","executionInfo":{"status":"ok","timestamp":1634949460131,"user_tz":300,"elapsed":157,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"d2618c33-9758-4615-f1ec-27ed2a7c1aa9"},"source":["#collapse-hide\n","\n","X = torch.arange(6)\n","info(X,\"X\")"],"execution_count":287,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X \n","\n","    num. dims        1\n","    num. entries     6\n","    shape            [6]\n","\n","\n","┌───┬───┬───┬───┬───┬───┐\n","│ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │\n","└───┴───┴───┴───┴───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnKJbrpVy7cX","executionInfo":{"status":"ok","timestamp":1634949463196,"user_tz":300,"elapsed":150,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"b4353234-376b-44d9-b2d8-327dca3749c0"},"source":["#collapse-hide\n","\n","X = X.view(2, 3)\n","info(X,\"X\")"],"execution_count":288,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌───┬───┬───┐\n","│ 0 │ 1 │ 2 │\n","├───┼───┼───┤\n","│ 3 │ 4 │ 5 │\n","└───┴───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ML1CxKBirIZN"},"source":["#### ... transposing tensors (permuting dimensions)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrcsGSx0rO-l","executionInfo":{"status":"ok","timestamp":1634949473302,"user_tz":300,"elapsed":145,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"25626ff7-246e-42b3-9e75-1ec54dee48b2"},"source":["#collapse-hide\n","\n","X = X.permute(1,0)\n","info(X,\"X with 0th and 1st dimensions permuted\")"],"execution_count":289,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X with 0th and 1st dimensions permuted \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [3 2]\n","\n","\n","┌───┬───┐\n","│ 0 │ 3 │\n","├───┼───┤\n","│ 1 │ 4 │\n","├───┼───┤\n","│ 2 │ 5 │\n","└───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"4S-Un1nuwJZw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634949483344,"user_tz":300,"elapsed":150,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"5e0f7c1a-bcff-43af-a0f0-65c5439c3983"},"source":["#collapse-hide\n","\n","X = X.T\n","info(X, \"X transposed again\")"],"execution_count":290,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X transposed again \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌───┬───┬───┐\n","│ 0 │ 1 │ 2 │\n","├───┼───┼───┤\n","│ 3 │ 4 │ 5 │\n","└───┴───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"oYiLwgu3rXvp"},"source":["#### ... numpy-like indexing and slicing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3ae8RldrbH7","executionInfo":{"status":"ok","timestamp":1634949489753,"user_tz":300,"elapsed":146,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"cb1c6f1c-a266-45f2-ec88-408001c1dbf0"},"source":["#collapse-hide\n","\n","X = torch.rand( 4,4 )\n","info( X, \"X\" )\n","info( X[0], \"first row of X\" )\n","info( X[:,0], \"first column of X\" )\n","info( X[...,-1], \"last column of X\" )\n","info( X[:2, -1], \"First two rows, last column\")\n","info( X[1:3, :], \"Middle two rows\" )"],"execution_count":291,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X \n","\n","    num. dims        2\n","    num. entries     16\n","    shape            [4 4]\n","\n","\n","┌──────┬──────┬──────┬──────┐\n","│ 0.90 │ 0.19 │ 0.46 │ 0.38 │\n","├──────┼──────┼──────┼──────┤\n","│ 0.58 │ 0.97 │ 0.54 │ 0.78 │\n","├──────┼──────┼──────┼──────┤\n","│ 0.88 │ 0.90 │ 0.32 │ 0.38 │\n","├──────┼──────┼──────┼──────┤\n","│ 0.74 │ 0.36 │ 0.73 │ 0.39 │\n","└──────┴──────┴──────┴──────┘\n","\n","\n","\n","tensor     first row of X \n","\n","    num. dims        1\n","    num. entries     4\n","    shape            [4]\n","\n","\n","┌──────┬──────┬──────┬──────┐\n","│ 0.90 │ 0.19 │ 0.46 │ 0.38 │\n","└──────┴──────┴──────┴──────┘\n","\n","\n","\n","tensor     first column of X \n","\n","    num. dims        1\n","    num. entries     4\n","    shape            [4]\n","\n","\n","┌──────┬──────┬──────┬──────┐\n","│ 0.90 │ 0.58 │ 0.88 │ 0.74 │\n","└──────┴──────┴──────┴──────┘\n","\n","\n","\n","tensor     last column of X \n","\n","    num. dims        1\n","    num. entries     4\n","    shape            [4]\n","\n","\n","┌──────┬──────┬──────┬──────┐\n","│ 0.38 │ 0.78 │ 0.38 │ 0.39 │\n","└──────┴──────┴──────┴──────┘\n","\n","\n","\n","tensor     First two rows, last column \n","\n","    num. dims        1\n","    num. entries     2\n","    shape            [2]\n","\n","\n","┌──────┬──────┐\n","│ 0.38 │ 0.78 │\n","└──────┴──────┘\n","\n","\n","\n","tensor     Middle two rows \n","\n","    num. dims        2\n","    num. entries     8\n","    shape            [2 4]\n","\n","\n","┌──────┬──────┬──────┬──────┐\n","│ 0.58 │ 0.97 │ 0.54 │ 0.78 │\n","├──────┼──────┼──────┼──────┤\n","│ 0.88 │ 0.90 │ 0.32 │ 0.38 │\n","└──────┴──────┴──────┴──────┘\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fqX_-7SsYYb","executionInfo":{"status":"ok","timestamp":1634949493974,"user_tz":300,"elapsed":142,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"4f933237-bf9c-4f1c-ac75-1c18d9c66c40"},"source":["#collapse-hide\n","\n","X[:,1] = 0\n","info(X, \"modified X\")"],"execution_count":292,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     modified X \n","\n","    num. dims        2\n","    num. entries     16\n","    shape            [4 4]\n","\n","\n","┌──────┬─────┬──────┬──────┐\n","│ 0.90 │ 0.0 │ 0.46 │ 0.38 │\n","├──────┼─────┼──────┼──────┤\n","│ 0.58 │ 0.0 │ 0.54 │ 0.78 │\n","├──────┼─────┼──────┼──────┤\n","│ 0.88 │ 0.0 │ 0.32 │ 0.38 │\n","├──────┼─────┼──────┼──────┤\n","│ 0.74 │ 0.0 │ 0.73 │ 0.39 │\n","└──────┴─────┴──────┴──────┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"cyVcUuRKuFA9"},"source":["#### ... other operations"]},{"cell_type":"markdown","metadata":{"id":"1PEj00HzuIFg"},"source":["Here are some ways to perform matrix multiplication:\n","\n","* `torch.matmul` $\\quad$ Performs the matrix product over two tensors, where the specific behavior depends on the dimensions.\n","If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product.\n","For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)).\n","\n","    It can also be written as `a @ b`, similar to numpy.\n","\n","* `torch.mm` $\\quad$ Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n","\n","* `torch.bmm` $\\quad$ Performs the matrix product with a support batch dimension. Let `T` be a tensor of shape `(b,  n, m)`, and `R` a tensor of shape `(b, m, p)`, the output tensor is of shape `(b, n , p)`, obtained by \"entry-wise\" matrix multiplication along the batch dimension. \n","\n","* `torch.einsum` $\\quad$ Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention.\n","\n","Usually, we use `torch.matmul` or `torch.bmm`. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClIpMlBPug0-","executionInfo":{"status":"ok","timestamp":1634949500331,"user_tz":300,"elapsed":150,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"a61cf5b5-56fb-43d2-c609-ebb6690b0b87"},"source":["#collapse-hide\n","\n","X, Y = torch.arange(6).view(2, 3), torch.arange(9).view(3, 3)\n","\n","info(X,\"X\")\n","\n","info(Y,\"Y\")\n"],"execution_count":293,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌───┬───┬───┐\n","│ 0 │ 1 │ 2 │\n","├───┼───┼───┤\n","│ 3 │ 4 │ 5 │\n","└───┴───┴───┘\n","\n","\n","\n","tensor     Y \n","\n","    num. dims        2\n","    num. entries     9\n","    shape            [3 3]\n","\n","\n","┌───┬───┬───┐\n","│ 0 │ 1 │ 2 │\n","├───┼───┼───┤\n","│ 3 │ 4 │ 5 │\n","├───┼───┼───┤\n","│ 6 │ 7 │ 8 │\n","└───┴───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tfE3Q4yIvZ6D","executionInfo":{"status":"ok","timestamp":1634949503821,"user_tz":300,"elapsed":137,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"dc08b1e5-0f83-4fd1-8883-62fcef06e593"},"source":["#collapse-hide\n","\n","Z = torch.matmul(X,Y)\n","info(Z, \"Z\")"],"execution_count":294,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     Z \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌────┬────┬────┐\n","│ 15 │ 18 │ 21 │\n","├────┼────┼────┤\n","│ 42 │ 54 │ 66 │\n","└────┴────┴────┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"rNkoOvNUwcD0"},"source":["Given a tensor `X`, the tensors `Y_1`,`Y_2`, `Y_3` computed below all have the same value:\n","\n","    Y_1 = X @ X.T\n","    Y_2 = X.matmul(X.T)\n","    Y_3 = torch.rand_like(X)\n","    torch.matmul(X, X.T, out = Y_3)"]},{"cell_type":"markdown","metadata":{"id":"hL9V6eauw54L"},"source":["On the other hand, `*` denotes the entrywise product of two tensors. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xD8EVlKhxGqC","executionInfo":{"status":"ok","timestamp":1634949510488,"user_tz":300,"elapsed":143,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"c1c13906-0862-4a49-f9c2-d73018d91239"},"source":["#collapse-hide\n","\n","X = torch.arange(6).view(2, 3)\n","info(X,\"X\")"],"execution_count":295,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     X \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌───┬───┬───┐\n","│ 0 │ 1 │ 2 │\n","├───┼───┼───┤\n","│ 3 │ 4 │ 5 │\n","└───┴───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhK2YS78xZQg","executionInfo":{"status":"ok","timestamp":1634949539714,"user_tz":300,"elapsed":170,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"32037375-303b-4dc7-8c6a-53469b70f90b"},"source":["#collapse-hide\n","\n","info( X * X, \"(a)\")\n","info( X.mul(X), \"(b)\")"],"execution_count":297,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     (a) \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌───┬────┬────┐\n","│ 0 │ 1  │ 4  │\n","├───┼────┼────┤\n","│ 9 │ 16 │ 25 │\n","└───┴────┴────┘\n","\n","\n","\n","tensor     (b) \n","\n","    num. dims        2\n","    num. entries     6\n","    shape            [2 3]\n","\n","\n","┌───┬────┬────┐\n","│ 0 │ 1  │ 4  │\n","├───┼────┼────┤\n","│ 9 │ 16 │ 25 │\n","└───┴────┴────┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"PX9GVY9_yOq3"},"source":["You can use `torch.cat` to concatenate a sequence of tensors along a given dimension. See also `torch.stack`, another tensor joining op that is subtly different from `torch.cat`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8ceai_hyU-K","executionInfo":{"status":"ok","timestamp":1634949550388,"user_tz":300,"elapsed":139,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"10ff8f54-e7a9-47fc-b4ec-ff534109821f"},"source":["#collapse-hide\n","\n","Y = torch.cat( [X, X, X], dim =1)\n","info(Y, \"Y\")"],"execution_count":298,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor     Y \n","\n","    num. dims        2\n","    num. entries     18\n","    shape            [2 9]\n","\n","\n","┌───┬───┬───┬───┬───┬───┬───┬───┬───┐\n","│ 0 │ 1 │ 2 │ 0 │ 1 │ 2 │ 0 │ 1 │ 2 │\n","├───┼───┼───┼───┼───┼───┼───┼───┼───┤\n","│ 3 │ 4 │ 5 │ 3 │ 4 │ 5 │ 3 │ 4 │ 5 │\n","└───┴───┴───┴───┴───┴───┴───┴───┴───┘\n","\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZFkFlehIymfT"},"source":["If you have a one-element tensor, for example obtained by aggregating all values of a given tensor into a single value, you can convert it to a Python numerical value using `item()`:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8AP_WDcyntl","executionInfo":{"status":"ok","timestamp":1634949557835,"user_tz":300,"elapsed":148,"user":{"displayName":"Julian Gold","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-WPTDjzM9OoEUntvRpUTCsTmARyNgiBOgQHfQ=s64","userId":"01597584131251118338"}},"outputId":"87ecc9db-4b13-46d6-9d4f-4bc583cedb66"},"source":["#collapse-hide\n","\n","agg = X.sum()\n","agg_item = agg.item() \n","print(agg_item, \"\\t\", type(agg_item))"],"execution_count":299,"outputs":[{"output_type":"stream","name":"stdout","text":["15 \t <class 'int'>\n"]}]},{"cell_type":"markdown","metadata":{"id":"-MK9npotqkY6"},"source":["## 2.2 ... Learning with scalar signals on a cyclic group"]},{"cell_type":"markdown","metadata":{"id":"Gl2miszAx3ki"},"source":["In the simplest setting we consider, the underlying domain is a one-dimensional grid, and the signals only have a single channel. We can identify this grid $\\Omega$ with the Cayley graph of cyclic group\n","$$\n","C_n = \\langle \\, a : a^n = 1 \\, \\rangle \\equiv \\{ \\, 1, a, a^2, \\dots, a^{n-1} \\, \\}.\n","$$\n","It is convenient to parametrize the group, and hence the grid, through the exponent of the generator \n","$$\n","C_n \\equiv \\{ 0, 1, \\dots, n -1 \\}\n","$$\n","as this indexing is consistent with the way most programming languages index vectors, reinterpreting the group operation as addition modulo $n$."]},{"cell_type":"markdown","metadata":{"id":"y1QX0iPUyVZd"},"source":["The vector space of single-channeled (i.e. real-valued) signals\n","$$\n","\\mathcal{X}(C_n,\\mathbb{R}) = \\{ x : C_n \\to \\mathbb{R} \\} ,\n","$$\n","is finite dimensional, and each $x \\in \\mathcal{X}(C_n, \\mathbb{R})$ may be expressed as \n","$$\n","x = \n","\\left[ \n","\\begin{matrix}\n","x_0\\\\ \n","\\vdots\\\\\n","\\,x_{n-1}\\,\n","\\end{matrix}\n","\\right] \n","$$\n","with respect to some implicit coordinate system used by the computer, the _input coordinate system_. This is the same coordinate system used to express the representation $\\rho$ of translation group $G \\equiv C_n$, which we now describe."]},{"cell_type":"markdown","metadata":{"id":"H-bA8Ykqywt4"},"source":["Given a vector $\\theta = (\\theta_0 , \\dots, \\theta_{n-1})$, recall the associated _circulant matrix_ is the $n \\times n$ matrix with entries \n","$$\n","\\mathcal{C}(\\theta) := \\left( \\, \\theta_{ (u - v) \\mod n} \\right)_{ 0 \\, \\leq \\,u,\\,v \\, \\leq n-1 } \n","$$"]},{"cell_type":"markdown","metadata":{"id":"_Ilur6U0zVps"},"source":["Consider the case of $\\theta_S := (0,1,0,\\dots, 0)^T$, the associated circulant matrix, $\\mathbf{S} := \\mathbf{C}(\\theta_S)$ acts on vectors by shifting the entries of vectors to the right by one position, modulo $n$. This is a shift or translation operator, which we denote $\\mathbf{S}$. "]},{"cell_type":"markdown","metadata":{"id":"VACCLRh_zaU2"},"source":["___\n","__Lemma__ $\\quad$\n","A matrix is circulant if and only if it commutes with $\\mathbf{S}$. Moreover, given any two vectors $\\theta, \\eta \\in \\mathbb{R}^n$, one has $\\mathbf{C}(\\theta) \\mathbf{C}(\\eta) = \\mathbf{C}(\\eta) \\mathbf{C}(\\theta)$. \n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"2BOxnG0Pz2YD"},"source":["The importance of $\\mathbf{S}$ to the present discussion is that it generates a group isomorphic to the one-dimensional translation group $C_n$. This is to say, a natural representation of $C_n = \\langle \\, a : a^n = 1 \\, \\rangle$ to consider is the group isomorphism induced by mapping the generator $a$ of $C_n$ to $\\mathbf{S}$. Specifically, the representation $\\rho$ of $G$ over $\\mathcal{X}( C_n, \\mathbb{R})$ is given by\n","$$\n","\\rho ( a^j ) := \\mathbf{S}^j \n","$$"]},{"cell_type":"markdown","metadata":{"id":"DTf8ASH40Qqb"},"source":["___\n","\n","__Corollary__ $\\quad$ Any $f : \\mathcal{X}(C_n, \\mathbb{R}) \\to \\mathcal{X}(C_n,\\mathbb{R})$ which is linear and $C_n$-equivariant can be expressed ( in the input coordinate system ) as an $n \\times n$ circulant matrix $\\mathbf{C}(\\theta)$ for some vector $\\theta$.\n","\n","___\n"]},{"cell_type":"markdown","metadata":{"id":"lu9LD2VC0nIT"},"source":["___\n","___\n","\n","__Example__ $\\quad$ \n","Our previous recipe for designing an equivariant function $F= \\Phi( \\mathbf{X}, \\mathbf{A})$ using a local aggregation function $\\varphi$. In this case, we can express\n","$$\n","\\varphi ( \\mathbf{x}_u, \\mathbf{X}_{\\mathcal{N}(u)} ) = \\varphi( \\mathbf{x}_{u-1}, \\, \\mathbf{x}_u, \\, \\mathbf{x}_{u+1} ),\n","$$\n","where the addition and subtraction in the indices above is understood to be modulo $n$. \n","\n"," If in addition, we insist that $\\varphi$ is linear, then it has the form \n","$$\n"," \\varphi( \\mathbf{x}_{u-1}, \\, \\mathbf{x}_u, \\, \\mathbf{x}_{u+1} ) = \\theta_{-1} \\mathbf{x}_{u-1} + \\theta_0 \\mathbf{x}_u + \\theta_1 \\mathbf{x}_{u+1},\n","$$\n","and in this case we can express $\\mathbf{F} = \\Phi (\\mathbf{X}, \\mathbf{A} )$ through the following matrix multiplication:\n","$$\n","\\left[\n","\\begin{matrix}\n","\\theta_0 & \\theta_1 & \\text{ } & \\text{ } & \\theta_{-1} \\\\\n","\\theta_{-1} & \\theta_0 & \\theta_1 & \\text{ } &   \\text{ } \\\\\n","\\text{} & \\ddots & \\ddots & \\ddots & \\text{ } \\\\\n","\\text{ } & \\text{ } & \\theta_{-1} & \\theta_0 & \\theta_1 \\\\\n","\\theta_1 & \\text{ } & \\text{ } & \\theta_{-1} & \\theta_0 \n","\\end{matrix} \n","\\right]\n","\\left[\n","\\begin{matrix}\n","\\mathbf{x}_0 \\\\\n","\\mathbf{x}_1 \\\\\n","\\vdots \\\\\n","\\,\\mathbf{x}_{n-2} \\, \\\\\n","\\mathbf{x}_{n-1}  \n","\\end{matrix}\n","\\right]\n","$$\n","This special multi-diagonal structure is sometimes referred to as ``weight sharing\" in the machine learning literature. \n","\n","___\n","___"]},{"cell_type":"markdown","metadata":{"id":"j0N6Rklm1Sn0"},"source":["Circulant matrices are synonymous with discrete convolutions; for $x \\in \\mathcal{X}(\\Omega,\\mathbb{R})$ and $\\theta \\in \\mathbb{R}^n$, their _convolution_ $x \\star \\theta$ is defined by \n","$$\n","( x \\star \\theta )_u := \\sum_{v = 0}^{n-1} x_{v \\mod n}\\, \\theta_{ (u-v) \\mod n}  \\, ,\n","$$\n","$$\n","\\equiv \\mathbf{C}(\\theta) x \n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"Lmh-AZIM1jXB"},"source":["___\n","\n","__Rmk__ $\\quad$ This leads to an alternate, equivalent definition of convolution as a translation equivariant linear operation. Moreover by replacing translations by a more general group $G$, one can generalize convolution to settings whose domain has symmetry other than translational. \n","___ "]},{"cell_type":"markdown","metadata":{"id":"njwaNoPCN09d"},"source":["#### `torch.nn.Conv2d`\n","\n","The arguments:\n","\n","* `in_channels`\n","\n","* `out_channels`\n","\n","* `kernel_size`\n","\n","* `stride` $\\quad$ controls the stride for the cross-correlation, a single number or a tuple. \n","\n","* `padding` $\\quad$ controls amount of padding applied to the input. It can either be a string, `\"valid\"` or `\"same\"` or a tuple of ints giving the amount of implicit padding applied on both sides. \n","\n","* `dilation` $\\quad$ controls the spacing between kernel points; \"also known as the a trous algorithm\n","\n","* `groups` $\\quad$ controls connections between inputs and outputs. The `in_channels` and `out_channels` must be divisible by `groups`. For example,\n","\n","    * At groups = 1, all inputs are convolved to all outputs\n","\n","    * At groups = 2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. \n","\n","    * At groups = `in_channels`, each input channel is convolved with its own set of filters (of size `out_channels // in_channels`)\n","\n","* `bias`\n","\n","* `padding_mode`,\n","\n","* `device`,\n","\n","* `dtype`"]},{"cell_type":"markdown","metadata":{"id":"8AIKdP8WPa9i"},"source":["Let us now relate the shapes of the input and output to the parameters\n","\n","\n","| input parameter      | LaTeX symbol |\n","| ----------- | ----------- |\n","| `in_channels`      | $\\text{dim}(\\mathcal{C})$     |\n","| `out_channels`   | $\\text{dim}(\\mathcal{C}_1)$        |\n","| `kernel_size`      | $k$       |\n","| `stride`   | $\\lambda$        |\n","| `padding`   | $\\rho$        |\n","| `dilation`      | $\\delta$       |\n","| `groups`   | $M$        \n","\n"]},{"cell_type":"markdown","metadata":{"id":"b7jNhkTvPgoH"},"source":["Additionally, we use $N$ for the batch size of the input, `N`. We also let $(h,w)$ denote the height-width pair describing the shape of the input signal domain. \n","\n","Correspondingly, we write $(h_1, w_1)$ for the height-width pair describing the shape of the output signal domain. "]},{"cell_type":"markdown","metadata":{"id":"hTqm3oVlPuGI"},"source":["We remark that the stride can be either integer or a $2$-tuple, whose coordinates describe the vertical and horizontal stride respectively. We still write $\\lambda$ for the stride when it is a tuple, and use $\\lambda_h \\equiv \\lambda[0]$ and $\\lambda_w \\equiv \\lambda[1]$ to denote its first and second coordinate, in this case. Likewise, the padding and kernel size may be $2$-tuples as well, and we use similar notation to denote their entries.  "]},{"cell_type":"markdown","metadata":{"id":"RNqduAQrPwZh"},"source":["The full shape of the input to the layer includes the batch dimension, and is thus\n","\n","$$\n","(N, \\text{dim}(\\mathcal{C}), H, W) \\,,\n","$$\n","\n","while the shape of the output is\n","\n","$$\n","(N , \\text{dim}(\\mathcal{C}_1), H_1, W_1 )\n","$$\n","\n","These shapes, in particular the spatial dimensions of each, are related as follows: \n","\n","$\\begin{align}\n","H_1 &= \\left\\lfloor \\frac{\n","    H + 2 \\rho_h - \\delta_h ( k_h -1) -1 }{\\lambda_h}\n","\\right\\rfloor \\\\\n","W_1 &= \\left\\lfloor \\frac{\n","    W + 2 \\rho_w - \\delta_w ( k_w -1) -1 }{\\lambda_w}\n","\\right\\rfloor\n","\\end{align}$,\n","\n","in particular, the batch size does not have any bearing on how the shapes of tensors transform. "]},{"cell_type":"markdown","metadata":{"id":"h4qqcExeP3OC"},"source":["The parameters to be learned are the weights $w^1$ and biases $b^1$. These are both `Tensor` objects, accessed from the layer as `Conv2d.weight` and `Conv2d.bias`. The shape of the weight tensor is\n","\n","$$\n","\\textrm{shape}(w^1) =\n","\\left( \\, \\text{dim}(\\mathcal{C}_1),  \\, \\text{dim}(\\mathcal{C}) \\big/ M , k_h, k_w \\right)\n","$$\n","\n","The tensor $w^1$ thus has \n","\n","$$\n","\\textrm{size}(w^1) = \\textrm{dim}(\\mathcal{C}_1) \\textrm{dim} (\\mathcal{C}) k_h k_w \\big/ M\n","$$\n","\n","scalar entries. \n","\n","There is always the question of how to initialize weights. In the case of the `Conv2d` class, the weights are initialized to be i.i.d. $\\text{Unif}( - \\sqrt{ \\alpha_1}, \\sqrt{\\alpha_1} )$ random variables, where\n","\n","$$\n","\\alpha_1 := \\frac{ \\textrm{dim}(\\mathcal{C}_1) }{\\textrm{size}(w^1)}\n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zQDEqpPSP-Cd"},"source":["The bias tensor is a much smaller object, we have \n","\n","$\n","\\begin{align}\n","\\textrm{shape}(b^1) = (\\, \\textrm{dim}(\\mathcal{C}_1  ) \\,) \\, , \\quad \\textrm{size}(b^1) = \\textrm{dim}(\\mathcal{C}_1)\n","\\end{align}\n","$"]},{"cell_type":"markdown","metadata":{"id":"N9IpVQKjQCAl"},"source":["Despite this, we use the same initialization (with mutual independence of all random variables in discussion) for the bias entries as we did for the weights. "]},{"cell_type":"markdown","metadata":{"id":"HRn89dm915m7"},"source":["## 2.2 ... A simple CNN"]},{"cell_type":"markdown","metadata":{"id":"_zxicBxC6VEw"},"source":["We consider possibly the simplest neural network that we can construct through the above blueprint. Suppose we have a binary classification problem, with the following hypothesis space. Let $\\textsf{H}_1$ denote the hypothesis space of functions $f : \\mathcal{X}( C_n, \\mathbb{R}) \\to \\{0,1\\}$ of the form \n","\n","$$\n","f = A \\circ P \\circ \\mathbf{a} \\circ B \\,,\n","$$\n","where the components of $f$ are "]},{"cell_type":"markdown","metadata":{"id":"g4DGJSDa6y2k"},"source":["where the components of $f$ are \n","\n","\n","* $B$  : $\\quad$ A $C_n$-equivariant function, to be learned. It is represented as a circulant matrix $\\mathbf{C}(\\theta)$, where $\\theta$ is a vector $\\theta \\equiv (\\theta_0, \\dots, \\theta_{n-1})$ whose entries $\\theta_j$ are parameters to be learned. \n","\n","* $ \\mathbf{a} $ : $\\quad$ We consider the ReLU activation function, $a : \\mathbb{R} \\to \\mathbb{R}_{\\geq\\, 0}$ defined by $a(w) = \\max(0,w)$, for $w \\in \\mathbb{R}$. The bold-face $\\mathbf{a}$ denotes the entry-wise action of this function on a given vector;for $y \\equiv (\\,y_1, \\,\\dots, \\, y_n \\, ) \\in \\mathcal{X}(C_n, \\mathbb{R})$, which we imagine as the output of $B(x)$ for some input signal $x$, we have $\\mathbf{a} (y ) = ( \\,  \\max(0,y_1), \\,  \\dots, \\, \\max(0,y_n) )$. There are no learned parameters in this layer. \n","\n","* $P$ : $\\quad$ A coarsening operator. In this case, let us say it is a _zero-padded group homomorphism_. \n","\n"," $P : C_n \\to C_{n / d }$ for some divisor $d \\mid n$ \\footnote{zero-padding} , and let us say that it operates through max-pooling on the signal, over the pre-images of each element of $C_{n / d}$. \n","\n","* $A$ : $\\quad$ A global-pooling layer. We assume this has the form of a fully-connected layer, followed by a softmax. Specifically,"]},{"cell_type":"code","metadata":{"id":"HjLRoZui8f2Y"},"source":[""],"execution_count":null,"outputs":[]}]}